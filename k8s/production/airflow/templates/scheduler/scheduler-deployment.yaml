---
# Source: airflow/templates/scheduler/scheduler-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  labels:
    app: airflow
    component: scheduler
    chart: airflow-8.7.1
    release: airflow
    heritage: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      ## multiple schedulers can run concurrently (Airflow 2.0)
      maxSurge: 25%
      maxUnavailable: 0
  selector:
    matchLabels:
      app: airflow
      component: scheduler
      release: airflow
  template:
    metadata:
      annotations:
        checksum/secret-config-envs: 417fb1258803452f520a433ffcbcc81cc94c440daca553a1bb2be210ea784716
        checksum/secret-local-settings: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
        checksum/config-pod-template: c4a33579a2135677ced731aa0c17c4c777d4b9e4d697aaaea6070c307453d861
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      labels:
        app: airflow
        component: scheduler
        release: airflow
    spec:
      restartPolicy: Always
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      securityContext:
        fsGroup: 0
      serviceAccountName: airflow
      initContainers:        
        - name: dags-git-clone
          image: registry.k8s.io/git-sync/git-sync:v3.6.5
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 65533
            runAsGroup: 65533
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 100m
              memory: 128Mi
          envFrom:    
            - secretRef:
                name: airflow-config-envs
          env:
            - name: GIT_SYNC_ONE_TIME
              value: "true"
            - name: GIT_SYNC_ROOT
              value: "/dags"
            - name: GIT_SYNC_DEST
              value: "repo"
            - name: GIT_SYNC_REPO
              value: "git@github.com:viniciusdsmello/airflow-k8s-gitsync.git"
            - name: GIT_SYNC_BRANCH
              value: "main"
            - name: GIT_SYNC_REV
              value: "HEAD"
            - name: GIT_SYNC_DEPTH
              value: "1"
            - name: GIT_SYNC_WAIT
              value: "60"
            - name: GIT_SYNC_TIMEOUT
              value: "120"
            - name: GIT_SYNC_ADD_USER
              value: "true"
            - name: GIT_SYNC_MAX_SYNC_FAILURES
              value: "0"
            - name: GIT_SYNC_SUBMODULES
              value: "recursive"
            - name: GIT_SYNC_SSH
              value: "true"
            - name: GIT_SSH_KEY_FILE
              value: "/etc/git-secret/id_rsa"
            - name: GIT_KNOWN_HOSTS
              value: "false"    
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-user
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-password
            - name: CONNECTION_CHECK_MAX_COUNT
              value: "0"
          volumeMounts:
            - name: dags-data
              mountPath: /dags
            - name: git-secret
              mountPath: /etc/git-secret/id_rsa
              readOnly: true
              subPath: id_rsa        
        - name: check-db  
          image: viniciusdsmello/airflow-k8s:v1.0.0
          imagePullPolicy: Always
          securityContext:
            runAsUser: 50000
            runAsGroup: 0
          envFrom:    
            - secretRef:
                name: airflow-config-envs
          env:    
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-user
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-password
            - name: CONNECTION_CHECK_MAX_COUNT
              value: "0"
          command:    
            - "/usr/bin/dumb-init"
            - "--"
            - "/entrypoint"
          args:
            - "bash"
            - "-c"
            - "exec timeout 60s airflow db check"
          volumeMounts:    
            - name: dags-data
              mountPath: /opt/airflow/dags
            - name: logs-data
              mountPath: /opt/airflow/logs
              subPath:         
        - name: wait-for-db-migrations  
          image: viniciusdsmello/airflow-k8s:v1.0.0
          imagePullPolicy: Always
          securityContext:
            runAsUser: 50000
            runAsGroup: 0
          envFrom:    
            - secretRef:
                name: airflow-config-envs
          env:    
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-user
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-password
            - name: CONNECTION_CHECK_MAX_COUNT
              value: "0"
          command:    
            - "/usr/bin/dumb-init"
            - "--"
            - "/entrypoint"
          args:
            - "bash"
            - "-c"
            - "exec airflow db check-migrations -t 60"
          volumeMounts:    
            - name: dags-data
              mountPath: /opt/airflow/dags
            - name: logs-data
              mountPath: /opt/airflow/logs
              subPath: 
      containers:
        - name: airflow-scheduler          
          image: viniciusdsmello/airflow-k8s:v1.0.0
          imagePullPolicy: Always
          securityContext:
            runAsUser: 50000
            runAsGroup: 0
          resources:
            limits:
              cpu: 4000m
              memory: 1.5Gi
            requests:
              cpu: 1000m
              memory: 1Gi
          envFrom:            
            - secretRef:
                name: airflow-config-envs
          env:            
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-user
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-password
            - name: CONNECTION_CHECK_MAX_COUNT
              value: "0"
          command:            
            - "/usr/bin/dumb-init"
            - "--"
            - "/entrypoint"
          args:
            - "bash"
            - "-c"
            - "exec airflow scheduler -n -1"
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            failureThreshold: 5
            timeoutSeconds: 60
            exec:
              command:                
                - "/usr/bin/dumb-init"
                - "--"
                - "/entrypoint"
                - "python"
                - "-Wignore"
                - "-c"
                - |
                  import os
                  import sys

                  # suppress logs triggered from importing airflow packages
                  os.environ["AIRFLOW__LOGGING__LOGGING_LEVEL"] = "ERROR"

                  # shared imports
                  try:
                      from airflow.jobs.job import Job
                  except ImportError:
                      # `BaseJob` was renamed to `Job` in airflow 2.6.0
                      from airflow.jobs.base_job import BaseJob as Job
                  from airflow.utils.db import create_session
                  from airflow.utils.net import get_hostname

                  # heartbeat check imports
                  try:
                      from airflow.jobs.scheduler_job_runner import SchedulerJobRunner
                  except ImportError:
                      # `SchedulerJob` is wrapped by `SchedulerJobRunner` since airflow 2.6.0
                      from airflow.jobs.scheduler_job import SchedulerJob as SchedulerJobRunner

                  with create_session() as session:
                      ########################
                      # heartbeat check
                      ########################
                      # ensure the SchedulerJob with most recent heartbeat for this `hostname` is alive
                      hostname = get_hostname()
                      scheduler_job = session \
                          .query(Job) \
                          .filter_by(job_type=SchedulerJobRunner.job_type) \
                          .filter_by(hostname=hostname) \
                          .order_by(Job.latest_heartbeat.desc()) \
                          .limit(1) \
                          .first()
                      if (scheduler_job is not None) and scheduler_job.is_alive():
                          pass
                      else:
                          sys.exit(f"The SchedulerJob (id={scheduler_job.id}) for hostname '{hostname}' is not alive")
          volumeMounts:            
            - name: dags-data
              mountPath: /opt/airflow/dags
            - name: logs-data
              mountPath: /opt/airflow/logs
              subPath: 
            - name: pod-template
              mountPath: /opt/airflow/pod_templates/pod_template.yaml
              subPath: pod_template.yaml
              readOnly: true        
        - name: dags-git-sync
          image: registry.k8s.io/git-sync/git-sync:v3.6.5
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 65533
            runAsGroup: 65533
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 100m
              memory: 128Mi
          envFrom:    
            - secretRef:
                name: airflow-config-envs
          env:
            - name: GIT_SYNC_ROOT
              value: "/dags"
            - name: GIT_SYNC_DEST
              value: "repo"
            - name: GIT_SYNC_REPO
              value: "git@github.com:viniciusdsmello/airflow-k8s-gitsync.git"
            - name: GIT_SYNC_BRANCH
              value: "main"
            - name: GIT_SYNC_REV
              value: "HEAD"
            - name: GIT_SYNC_DEPTH
              value: "1"
            - name: GIT_SYNC_WAIT
              value: "60"
            - name: GIT_SYNC_TIMEOUT
              value: "120"
            - name: GIT_SYNC_ADD_USER
              value: "true"
            - name: GIT_SYNC_MAX_SYNC_FAILURES
              value: "0"
            - name: GIT_SYNC_SUBMODULES
              value: "recursive"
            - name: GIT_SYNC_SSH
              value: "true"
            - name: GIT_SSH_KEY_FILE
              value: "/etc/git-secret/id_rsa"
            - name: GIT_KNOWN_HOSTS
              value: "false"    
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-user
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres
                  key: postgresql-password
            - name: CONNECTION_CHECK_MAX_COUNT
              value: "0"
          volumeMounts:
            - name: dags-data
              mountPath: /dags
            - name: git-secret
              mountPath: /etc/git-secret/id_rsa
              readOnly: true
              subPath: id_rsa
      volumes:        
        - name: dags-data
          emptyDir: {}
        - name: logs-data
          persistentVolumeClaim:
            claimName: airflow-logs
        - name: git-secret
          secret:
            secretName: airflow-gitsync
            defaultMode: 0644
        - name: pod-template
          configMap:
            name: airflow-pod-template
